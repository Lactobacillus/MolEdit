{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45e1463-c2e1-4683-934d-942e9f1c0843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"False\"\n",
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "import math\n",
    "import pickle as pkl \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"We are now running Python in: \", sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaa220f-744d-4e17-80a0-e186ec8f7408",
   "metadata": {},
   "source": [
    "## Preparation (nets, constants, params and functional utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcd28e3-580b-4040-bb5a-945dbaf4500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax \n",
    "import jax.numpy as jnp\n",
    "\n",
    "from functools import partial\n",
    "from cybertron.common.config_load import load_config\n",
    "\n",
    "#### load nets\n",
    "from train.train import MolEditScoreNet\n",
    "from cybertron.model.molct_plus import MolCT_Plus\n",
    "from cybertron.readout import GFNReadout\n",
    "\n",
    "from train.utils import set_dropout_rate_config\n",
    "from jax.sharding import PositionalSharding\n",
    "\n",
    "def _sharding(input, shards):\n",
    "\n",
    "    n_device = shards.shape[0]\n",
    "    if isinstance(input, (np.ndarray, jax.Array)):\n",
    "        _shape = [n_device, ] + [1 for _ in range(input.ndim - 1)]\n",
    "        return jax.device_put(input, shards.reshape(_shape))\n",
    "    elif input is None:\n",
    "        return jax.device_put(input, shards)\n",
    "    else:\n",
    "        raise TypeError(f\"Invalid input: {input}\")\n",
    "\n",
    "from inference.inference import DPM_3_inference, Langevin_inference, DPM_pp_2S_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601104c1-524b-491e-a689-b891de0aab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "NDEVICES = 1\n",
    "NATOMS = 64\n",
    "SHARDING = True #### you can use multiple devices\n",
    "if SHARDING:\n",
    "    NDEVICES = len(jax.devices())\n",
    "    print(\"{} DEVICES detected: {}\".format(NDEVICES, jax.devices()))\n",
    "\n",
    "def split_rngs(rng_key, shape):\n",
    "    size = np.prod(shape)\n",
    "    rng_keys = jax.random.split(rng_key, size + 1)\n",
    "    return rng_keys[:-1].reshape(shape + (-1,)), rng_keys[-1]\n",
    "\n",
    "rng_key = jax.random.PRNGKey(8888) #### set your random seed here\n",
    "np.random.seed(7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a94c858-fa65-4cd3-a4f6-904710de7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### initialize models (structure diffusion model)\n",
    "encoder_config = load_config(\"../config/molct_plus.yaml\")\n",
    "gfn_config = load_config(\"../config/gfn.yaml\")\n",
    "gfn_config.settings.n_interactions = 4\n",
    "\n",
    "modules = {\n",
    "    \"encoder\": {\"module\": MolCT_Plus, \n",
    "                \"args\": {\"config\": encoder_config}},\n",
    "    \"gfn\": {\"module\": GFNReadout, \n",
    "            \"args\": {\"config\": gfn_config}}\n",
    "}\n",
    "\n",
    "##### load params\n",
    "load_ckpt_paths = ['../params/ZINC_3m/structure_model/moledit_params_track1.pkl', \n",
    "                   '../params/ZINC_3m/structure_model/moledit_params_track2.pkl',\n",
    "                   '../params/ZINC_3m/structure_model/moledit_params_track3.pkl'] \n",
    "noise_thresholds = [0.35, 1.95]\n",
    "\n",
    "params = []\n",
    "for path in load_ckpt_paths:\n",
    "    with open(path, 'rb') as f: \n",
    "        params.append(pkl.load(f))\n",
    "    \n",
    "if SHARDING:\n",
    "    ##### replicate params\n",
    "    global_sharding = PositionalSharding(jax.devices()).reshape(NDEVICES, 1)\n",
    "    params = jax.device_put(params, global_sharding.replicate())\n",
    "\n",
    "for k, v in modules.items():\n",
    "    modules[k]['args']['config'] = \\\n",
    "        set_dropout_rate_config(modules[k]['args']['config'], 0.0)\n",
    "    modules[k][\"module\"] = v[\"module\"](**v[\"args\"])\n",
    "    modules[k][\"callable_fn\"] = [] \n",
    "    for param in params:\n",
    "        partial_params = {\"params\": param[\"params\"]['score_net'].pop(k)}\n",
    "        modules[k][\"callable_fn\"].append(partial(modules[k][\"module\"].apply, partial_params))\n",
    "\n",
    "moledit_scorenets = [MolEditScoreNet(\n",
    "        encoder=modules['encoder']['callable_fn'][k],\n",
    "        gfn=modules['gfn']['callable_fn'][k],\n",
    "    ) for k in range(len(load_ckpt_paths))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e35ead4-b13d-4700-9c65-032e5651145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### initialize models (constituents model)\n",
    "from config.transformer_config import transformer_config\n",
    "from transformer.model import Transformer, TransformerConfig\n",
    "\n",
    "with open('../params/ZINC_3m/constituents_model/constituents_vocab.pkl', 'rb') as f:\n",
    "    constituent_vocab_list = pkl.load(f)\n",
    "NCONSTITUENTS = len(constituent_vocab_list) # 38\n",
    "NRG_TOKENS = 3 # seq_len = 38 + 3\n",
    "SEQ_LEN = NCONSTITUENTS + NRG_TOKENS\n",
    "\n",
    "NRG_VOCABS = 11\n",
    "transformer_config.deterministic = True\n",
    "transformer_config.dtype = jnp.float32\n",
    "transformer = Transformer(\n",
    "    config=TransformerConfig(\n",
    "            **{\n",
    "                **transformer_config,\n",
    "                \"vocab_size\": NATOMS + NRG_VOCABS + 1, \n",
    "                \"output_vocab_size\": NATOMS + NRG_VOCABS + 1}, )\n",
    ")\n",
    "\n",
    "##### load params\n",
    "with open(\"../params/ZINC_3m/constituents_model/moledit_params.pkl\", \"rb\") as f:\n",
    "    params = pkl.load(f)\n",
    "    params = jax.tree_util.tree_map(lambda x: jnp.array(x), params)\n",
    "\n",
    "if SHARDING:\n",
    "    ##### replicate params\n",
    "    global_sharding = PositionalSharding(jax.devices()).reshape(NDEVICES, 1)\n",
    "    params = jax.device_put(params, global_sharding.replicate())\n",
    "\n",
    "def top_p_sampling(logits, rng_key, p=0.9):\n",
    "    sorted_indices = jnp.argsort(logits)\n",
    "    sorted_logits = logits[sorted_indices]\n",
    "    sorted_probs = jax.nn.softmax(sorted_logits)\n",
    "    cum_probs = jnp.cumsum(sorted_probs)\n",
    "    invalid_mask = cum_probs < (1-p)\n",
    "    \n",
    "    rng_key, sample_key = jax.random.split(rng_key)\n",
    "    sampled_token = jax.random.categorical(sample_key, sorted_logits+invalid_mask.astype(jnp.float32)*(-1e5))\n",
    "    \n",
    "    return sorted_indices[sampled_token], rng_key \n",
    "        \n",
    "##### prepare functions, jit & vmap\n",
    "jitted_logits_fn = jax.jit(transformer.apply)\n",
    "top_p_sampling_fn = jax.vmap(jax.vmap(jax.jit(partial(top_p_sampling, p=0.9))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178286a2-3d12-4dfb-b331-8cd85f369ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "def SMILES_to_constituents(smi):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    mol = Chem.RemoveAllHs(mol)\n",
    "    atomic_numbers = np.array([atom.GetAtomicNum() for atom in mol.GetAtoms()], dtype=np.uint8)\n",
    "    hydrogen_numbers = np.array([atom.GetTotalNumHs() for atom in mol.GetAtoms()], dtype=np.uint8)\n",
    "    hybridizations = np.array([atom.GetHybridization() for atom in mol.GetAtoms()], dtype=np.uint8)\n",
    "\n",
    "    bond_ids = np.array([(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()) for bond in mol.GetBonds()], dtype=np.uint8)\n",
    "    bond_types = np.array([int(bond.GetBondType()) for bond in mol.GetBonds()], dtype=np.uint8)\n",
    "    \n",
    "    topology = {i: {} for i in range(len(atomic_numbers))}\n",
    "    for (atom_i, atom_j), bond_type in zip(bond_ids, bond_types):\n",
    "        topology[atom_i][atom_j] = topology[atom_j][atom_i] = bond_type\n",
    "    \n",
    "    constituents_dict = {\n",
    "        \"atomic_numbers\": atomic_numbers,\n",
    "        \"hydrogen_numbers\": hydrogen_numbers,\n",
    "        \"hybridizations\": hybridizations,\n",
    "        \"bonds\": topology,\n",
    "    }\n",
    "\n",
    "    return constituents_dict\n",
    "\n",
    "def RDMol_to_constituents_and_structure(mol):\n",
    "    mol = Chem.RemoveAllHs(mol)\n",
    "    atomic_numbers = np.array([atom.GetAtomicNum() for atom in mol.GetAtoms()], dtype=np.uint8)\n",
    "    hydrogen_numbers = np.array([atom.GetTotalNumHs() for atom in mol.GetAtoms()], dtype=np.uint8)\n",
    "    hybridizations = np.array([atom.GetHybridization() for atom in mol.GetAtoms()], dtype=np.uint8)\n",
    "\n",
    "    bond_ids = np.array([(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()) for bond in mol.GetBonds()], dtype=np.uint8)\n",
    "    bond_types = np.array([int(bond.GetBondType()) for bond in mol.GetBonds()], dtype=np.uint8)\n",
    "    \n",
    "    topology = {i: {} for i in range(len(atomic_numbers))}\n",
    "    for (atom_i, atom_j), bond_type in zip(bond_ids, bond_types):\n",
    "        topology[atom_i][atom_j] = topology[atom_j][atom_i] = bond_type\n",
    "    \n",
    "    constituents_dict = {\n",
    "        \"atomic_numbers\": atomic_numbers,\n",
    "        \"hydrogen_numbers\": hydrogen_numbers,\n",
    "        \"hybridizations\": hybridizations,\n",
    "        \"bonds\": topology,\n",
    "    }\n",
    "\n",
    "    for c in mol.GetConformers():\n",
    "        structure = np.array(c.GetPositions())\n",
    "\n",
    "    return constituents_dict, structure\n",
    "\n",
    "def mol_with_index(mol):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range(atoms):\n",
    "        mol.GetAtomWithIdx(idx).SetProp('molAtomMapNumber', str(mol.GetAtomWithIdx(idx).GetIdx()))\n",
    "\n",
    "    return mol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41627963-a976-4d37-bad2-bf36a5945a87",
   "metadata": {},
   "source": [
    "## Structure Rendring & Sampling of Textual Representations (SMILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0206331c-a380-4065-81ec-63ae8c3596c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NSAMPLE_PER_DEVICE = 16 # 1 / 8\n",
    "NSTRUCTURE_PER_SAMPLE = 8 # 1024 is used in evaluation\n",
    "NSAMPLES = 128 # 1024 is used in evaluation\n",
    "NSAMPLE_PER_BATCH = int(NSAMPLE_PER_DEVICE * NDEVICES)\n",
    "NSTRUCTURE_PER_BATCH = NSTRUCTURE_PER_SAMPLE * NSAMPLE_PER_BATCH\n",
    "NBATCHES = NSAMPLES // NSAMPLE_PER_BATCH\n",
    "NSTRUCTURES = NSAMPLES * NSTRUCTURE_PER_SAMPLE\n",
    "INFERENCE_METHOD = \"DPM_3\"\n",
    "\n",
    "print(\"NSAMPLE_PER_DEVICE: {}\".format(NSAMPLE_PER_DEVICE))\n",
    "print(\"NSAMPLES: {}\".format(NSAMPLES))\n",
    "print(\"NSAMPLE_PER_BATCH: {}\".format(NSAMPLE_PER_BATCH))\n",
    "print(\"NBATCHES: {}\".format(NBATCHES))\n",
    "\n",
    "#### jit and vmap functions\n",
    "def score_forward_fn(atom_feat, bond_feat, x, atom_mask, sigma, rg, gamma=1.0):\n",
    "    cond_list = [sigma < noise_thresholds[0],] + \\\n",
    "                [jnp.logical_and(sigma >= noise_thresholds[i], sigma < noise_thresholds[i+1]) for i in range(0, len(noise_thresholds) - 1)] + \\\n",
    "                [sigma >= noise_thresholds[-1],]\n",
    "    value_list = [net.apply(\n",
    "                    {}, atom_feat, bond_feat, x, atom_mask, sigma, rg)[-1] for net in moledit_scorenets]\n",
    "    value_unc_list = [net.apply(\n",
    "                    {}, atom_feat, jnp.zeros_like(bond_feat), x, atom_mask, sigma, rg)[-1] for net in moledit_scorenets]\n",
    "    value = gamma * jnp.array(value_list, jnp.float32) +\\\n",
    "                (1.0 - gamma) * jnp.array(value_unc_list, jnp.float32)\n",
    "    \n",
    "    return jnp.sum(jnp.array(cond_list, dtype=jnp.float32)[..., None, None] * value, axis=0)\n",
    "\n",
    "score_forward_fn_jvj = jax.jit(jax.vmap(jax.jit(score_forward_fn)))\n",
    "if INFERENCE_METHOD == \"DPM_3\":\n",
    "    inference_fn = partial(DPM_3_inference, score_fn=score_forward_fn_jvj, \n",
    "                           n_steps=20, shard_inputs=SHARDING)\n",
    "elif INFERENCE_METHOD == \"DPM_pp_2S\":\n",
    "    inference_fn = partial(DPM_pp_2S_inference, score_fn=score_forward_fn_jvj, \n",
    "                           n_steps=20, shard_inputs=SHARDING)\n",
    "elif INFERENCE_METHOD == \"Langevin\":\n",
    "    inference_fn = partial(Langevin_inference, score_fn=score_forward_fn_jvj, \n",
    "                           n_steps=1000, shard_inputs=SHARDING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee1631b-4979-4df2-9dc4-6cae31937c54",
   "metadata": {},
   "source": [
    "### Test SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941d720d-d0ea-42d1-94fe-864e26062226",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../moledit_dataset/smileses/geodiff_test_smileses.pkl', 'rb') as f:\n",
    "    test_smileses = [str(x).strip() for x in pkl.load(f)[:NSAMPLES]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4580ea6-76a8-4128-97a0-bdd991fe24b5",
   "metadata": {},
   "source": [
    "### Constituents Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc5859c-b05b-47a7-8642-0fc7590087b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "constituents_dicts = {}\n",
    "constituents_arrs = []\n",
    "\n",
    "### preprocess smiles\n",
    "for i, smi in tqdm(enumerate(test_smileses)):\n",
    "    constituents_dict = SMILES_to_constituents(smi)\n",
    "    constituents_dicts[smi] = constituents_dict\n",
    "\n",
    "    #### sample rg \n",
    "    constituents_str = np.array([\"{}_{}_{}\".format(i,j,k) for i,j,k in zip(constituents_dict['atomic_numbers'], \n",
    "                                                                           constituents_dict['hydrogen_numbers'], \n",
    "                                                                           constituents_dict['hybridizations'])])\n",
    "    constituents_arrs.append(np.array([np.sum(constituents_str == v) for v in constituent_vocab_list]))\n",
    "constituents_arrs = jnp.array(constituents_arrs, dtype=jnp.int32)\n",
    "\n",
    "### sample rgs\n",
    "input_dict = {\n",
    "    \"inputs\": jnp.ones((NSTRUCTURES, SEQ_LEN), dtype=jnp.int32), \n",
    "    \"generation_result\": jnp.ones((NSTRUCTURES, SEQ_LEN), dtype=jnp.int32)\n",
    "}\n",
    "input_dict[\"generation_result\"] = input_dict[\"generation_result\"].at[:, :NCONSTITUENTS].set(\n",
    "                                            jnp.repeat(constituents_arrs, NSTRUCTURE_PER_SAMPLE, axis=0) + 1)\n",
    "input_dict[\"inputs\"] = input_dict[\"inputs\"].at[:, NCONSTITUENTS:].set(NATOMS + NRG_VOCABS) #### unk token for rg\n",
    "\n",
    "inv_temperature = 1.25\n",
    "generation_results = []\n",
    "rng_keys, rng_key = split_rngs(rng_key, (NBATCHES, ))\n",
    "for b in tqdm(range(NBATCHES)):\n",
    "    input_dict_ = jax.tree_map(lambda x:x[b*NSTRUCTURE_PER_BATCH:(b+1)*NSTRUCTURE_PER_BATCH], input_dict)\n",
    "    rng_key_b = rng_keys[b]\n",
    "    rng_keys_b, _ = split_rngs(rng_key_b, (NSTRUCTURE_PER_BATCH, SEQ_LEN))\n",
    "    \n",
    "    if SHARDING:\n",
    "        #### shard inputs \n",
    "        ds_sharding = partial(_sharding, shards=global_sharding)\n",
    "        input_dict_ = jax.tree_map(ds_sharding, input_dict_)\n",
    "        rng_keys_b = ds_sharding(rng_keys_b)\n",
    "\n",
    "    \n",
    "    for step in range(NCONSTITUENTS, SEQ_LEN):\n",
    "        logits = jitted_logits_fn(params, \n",
    "                                  input_dict_['inputs'],\n",
    "                                  input_dict_['generation_result'])\n",
    "        valid_logits_mask = jnp.zeros_like(logits, dtype=jnp.float32).at[..., -NRG_VOCABS:-1].set(1)\n",
    "        logits += (-1e5) * (1.0 - valid_logits_mask)\n",
    "        sampled_token, rng_keys_b = top_p_sampling_fn(logits * inv_temperature, rng_keys_b)\n",
    "        input_dict_['generation_result'] = \\\n",
    "            input_dict_['generation_result'].at[..., step].set(sampled_token[..., step])\n",
    "    generation_results.append(input_dict_['generation_result'])\n",
    "    \n",
    "generation_result = np.array(jnp.concatenate(generation_results, axis=0)) - 1\n",
    "for i, (smi, seqs) in tqdm(enumerate(zip(test_smileses, generation_result.reshape(NSAMPLES,NSTRUCTURE_PER_SAMPLE,-1)))):    \n",
    "    #### decode rg\n",
    "    rg_seqs = seqs[:, -NRG_TOKENS:] - NATOMS\n",
    "    rgs = []\n",
    "    for rg_seq in rg_seqs:\n",
    "        rg = np.exp(rg_seq[0]) * float(\"{}.{}\".format(rg_seq[1], \"\".join([str(x) for x in rg_seq[2:]])))\n",
    "        rgs.append(rg)\n",
    "    constituents_dicts[smi].update({\"radius_of_gyrations\": np.array(rgs, dtype=np.float32)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238e977a-0f4f-4f9f-bffa-1a0ad2fc6c50",
   "metadata": {},
   "source": [
    "### Structure Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6046071-7c40-4719-912d-ef915ddb96da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example constituents: \")\n",
    "print(\"\\tatomic numbers: \", constituents_dicts[test_smileses[0]]['atomic_numbers'])\n",
    "print(\"\\thydrogen numbers: \", constituents_dicts[test_smileses[0]]['hydrogen_numbers'])\n",
    "print(\"\\thybridizaions: \", constituents_dicts[test_smileses[0]]['hybridizations'])\n",
    "print(\"\\tradius of gyrations: \", constituents_dicts[test_smileses[0]]['radius_of_gyrations'])\n",
    "print(\"\\tbonds: \", constituents_dicts[test_smileses[0]]['bonds'])\n",
    "print(\"\\t**REMARK**: hybridization symbols are same with RDkit\")\n",
    "\n",
    "from inference.utils import preprocess_data\n",
    "\n",
    "print(\"Preprocessing inputs\")\n",
    "input_dicts = []\n",
    "for smi in tqdm(test_smileses):\n",
    "    d = constituents_dicts[smi]\n",
    "    input_dicts.extend([preprocess_data({**{k: v for k, v in d.items() if k != 'radius_of_gyrations'}, \n",
    "                                         \"radius_of_gyrations\": [d['radius_of_gyrations'][i]]}, NATOMS) for i in range(NSTRUCTURE_PER_SAMPLE)])\n",
    "input_dict = {\n",
    "    k: np.stack([d[k] for d in input_dicts]) for k in input_dicts[0].keys()\n",
    "}\n",
    "\n",
    "print(\"input shape & dtypes: \")\n",
    "for k, v in input_dict.items():\n",
    "    print(\"\\t{} shape: {} dtype: {}\".format(k, v.shape, v.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fa8b20-35d3-490a-ba4f-355ac9fcf6bc",
   "metadata": {},
   "source": [
    "#### With DPM Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c7647b-d908-43a4-a9b9-cfd27452d1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_keys, rng_key = split_rngs(rng_key, (NBATCHES,))\n",
    "input_dict = jax.tree_map(lambda x:jnp.array(x), input_dict)\n",
    "structures, trajectories = [], []\n",
    "\n",
    "#### JAX compiles a jitted function when you call it first time.\n",
    "### so it will be slow when you run this block first time.\n",
    "print(\"inference requires {} batches running on {} GPUs\".format(NBATCHES, NDEVICES))\n",
    "for b in range(NBATCHES):\n",
    "    structures_, trajectories_, _ = inference_fn(\n",
    "        jax.tree_map(lambda x:x[b*NSTRUCTURE_PER_BATCH:(b+1)*NSTRUCTURE_PER_BATCH], input_dict), rng_keys[b])\n",
    "    structures.append(structures_)\n",
    "    # trajectories.append(trajectories_) # if you want to save trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae505a4-5828-4e8e-8d1a-3f50459c19f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = np.array(structures).reshape(NSAMPLES, NSTRUCTURE_PER_SAMPLE, NATOMS, 3)\n",
    "trajectories = np.array(trajectories).transpose((1, 0, 2, 3, 4)).reshape(-1, NSAMPLES, NSTRUCTURE_PER_SAMPLE, NATOMS, 3) if len(trajectories) > 0 \\\n",
    "                else np.array(trajectories)\n",
    "# structures, trajectories = [], []\n",
    "\n",
    "#### save results \n",
    "with open(f'../results/structure_rendering/result_geodiff_test_smiles.pkl', 'wb') as f: \n",
    "    pkl.dump(jax.tree_map(np.array, \n",
    "                          {'smiles': test_smileses,\n",
    "                           'constituents': [{k: constituents_dicts[smi][k] for k in constituents_dicts[smi].keys() if k != 'bonds'} \n",
    "                                            for smi in  test_smileses],\n",
    "                           'conditional_infos': [{'bonds': constituents_dicts[smi]['bonds']} for smi in test_smileses],  \n",
    "                           'trajectories': trajectories, \n",
    "                           'structures': structures}), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f37fe47-1ab6-4484-a0f4-e4417abaaf7e",
   "metadata": {},
   "source": [
    "#### With FPS Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9404685a-c224-4e02-ab60-c4f453a46da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Xponge\n",
    "from Xponge.helper import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Lipinski import RotatableBondSmarts\n",
    "from rdkit.Geometry import Point3D\n",
    "from rdkit.Chem import rdMolTransforms\n",
    "\n",
    "def get_rotable_dihedrals(mol):\n",
    "    bond_ids = np.array([(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()) for bond in mol.GetBonds()], dtype=np.uint8)\n",
    "    bond_types = np.array([int(bond.GetBondType()) for bond in mol.GetBonds()], dtype=np.uint8)\n",
    "    bonds = {i: {} for i in range(len(mol.GetAtoms()))}\n",
    "    for ((atom_i, atom_j), bond_type) in zip(bond_ids, bond_types):\n",
    "        bonds[atom_i][atom_j] = bonds[atom_j][atom_i] = bond_type\n",
    "\n",
    "    rotable_bonds = mol.GetSubstructMatches(RotatableBondSmarts)\n",
    "    rotable_bonds_dihedral_ids = []\n",
    "    for (atom_j, atom_k) in rotable_bonds:\n",
    "        for atom_i in bonds[atom_j].keys():\n",
    "            if atom_i == atom_k: continue \n",
    "            for atom_l in bonds[atom_k].keys():\n",
    "                if atom_l == atom_j: continue\n",
    "                rotable_bonds_dihedral_ids.append([atom_i, atom_j, atom_k, atom_l])\n",
    "    return np.array(rotable_bonds_dihedral_ids, dtype=np.int32)\n",
    "\n",
    "mol = Chem.MolFromSmiles(test_smileses[0])\n",
    "rotable_bonds_dihedral_ids = get_rotable_dihedrals(mol)\n",
    "rotable_bonds_dihedral_ids = jnp.array(rotable_bonds_dihedral_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d5796-a003-44af-bc84-649f3070856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_coeff = 2e3  ### This coeficient controls the additional Fokker-Planck-gradient term in SDE\n",
    "rng_keys, rng_key = split_rngs(rng_key, (NBATCHES,))\n",
    "input_dict = jax.tree_map(lambda x:jnp.array(x), input_dict)\n",
    "structures, trajectories = [], []\n",
    "\n",
    "#### JAX compiles a jitted function when you call it first time.\n",
    "### so it will be slow when you run this block first time.\n",
    "print(\"inference requires {} batches running on {} GPUs\".format(NBATCHES, NDEVICES))\n",
    "for b in range(NBATCHES):\n",
    "    structures_, trajectories_, _ = inference_fn(\n",
    "        jax.tree_map(lambda x:x[b*NSTRUCTURE_PER_BATCH:(b+1)*NSTRUCTURE_PER_BATCH], input_dict), rng_keys[b], \n",
    "        dihedral_dict={'dihedral_atom_ids': rotable_bonds_dihedral_ids, 'fp_coeff': fp_coeff})\n",
    "    structures.append(structures_)\n",
    "    # trajectories.append(trajectories_) # if you want to save trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b62bde-8c81-4dec-a422-ca862c73d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = np.array(structures).reshape(NSAMPLES, NSTRUCTURE_PER_SAMPLE, NATOMS, 3)\n",
    "trajectories = np.array(trajectories).transpose((1, 0, 2, 3, 4)).reshape(-1, NSAMPLES, NSTRUCTURE_PER_SAMPLE, NATOMS, 3) if len(trajectories) > 0 \\\n",
    "                else np.array(trajectories)\n",
    "# structures, trajectories = [], []\n",
    "\n",
    "#### save results \n",
    "with open(f'../results/structure_rendering/result_geodiff_test_smiles_fps.pkl', 'wb') as f: \n",
    "    pkl.dump(jax.tree_map(np.array, \n",
    "                          {'smiles': test_smileses,\n",
    "                           'constituents': [{k: constituents_dicts[smi][k] for k in constituents_dicts[smi].keys() if k != 'bonds'} \n",
    "                                            for smi in  test_smileses],\n",
    "                           'conditional_infos': [{'bonds': constituents_dicts[smi]['bonds']} for smi in test_smileses],  \n",
    "                           'trajectories': trajectories, \n",
    "                           'structures': structures}), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f24b460-8cd3-40b0-86c6-8b7af821f9d4",
   "metadata": {},
   "source": [
    "### View Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea65ddd-c432-4805-acc2-fa01e29325ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### view trajectories | structures\n",
    "import MDAnalysis as mda \n",
    "import nglview as nv \n",
    "\n",
    "#### load your results \n",
    "with open(f'../results/structure_rendering/result_geodiff_test_smiles.pkl', 'rb') as f:\n",
    "# with open(f'results/structure_rendering/result_geodiff_test_smiles_fps.pkl', 'rb') as f:\n",
    "    results = pkl.load(f)\n",
    "    test_smileses = results['smiles']\n",
    "    constituents = results['constituents']\n",
    "    conditional_infos = results['conditional_infos']\n",
    "    # trajectories = results['trajectories']\n",
    "    structures = results['structures']\n",
    "\n",
    "elements = {\n",
    "    6: 'C', 7: 'N', 8: 'O', 9: 'F', 15: 'P', 16: 'S', 17: 'Cl', \n",
    "    35: 'Br', 53: 'I'\n",
    "}\n",
    "\n",
    "mol_id, structure_id = 0, 0\n",
    "print(\"smiles: \", test_smileses[mol_id], len(test_smileses))\n",
    "atomic_numbers = constituents[mol_id]['atomic_numbers']\n",
    "hydrogen_numbers = constituents[mol_id]['hydrogen_numbers']\n",
    "hybridizations = constituents[mol_id]['hybridizations']\n",
    "print(\"atomic numbers:\", \",\".join([str(x) for x in atomic_numbers]))\n",
    "print(\"hydrogen_numbers:\", \",\".join([str(x) for x in hydrogen_numbers]))\n",
    "print(\"hybridizations:\", \",\".join([str(x) for x in hybridizations]))\n",
    "n_atoms = len(atomic_numbers)\n",
    "# trajectory = np.array(trajectories)[:, mol_id, structure_id, :n_atoms, :]\n",
    "structure = np.array(structures)[mol_id, structure_id, :n_atoms, :]\n",
    "rg = np.sqrt(np.sum(structure ** 2) / n_atoms)\n",
    "print(\"This is a molecule with {} atoms, rg = {:.2f}/{:.2f} ang\".format(n_atoms, rg, constituents[mol_id]['radius_of_gyrations'][structure_id]))\n",
    "print(\"Conditional infos indicate the following bonds\")\n",
    "print(\"WARNING: bonds provided by NGLViewer may be problematic\")\n",
    "\n",
    "mol = mda.Universe.empty(n_atoms=len(atomic_numbers))\n",
    "mol.add_TopologyAttr('names', [\"{}{}\".format(elements[n], i) for i, n in enumerate(atomic_numbers)])\n",
    "# mol.add_TopologyAttr('names', [\"{}\".format(elements[n]) for i, n in enumerate(atomic_numbers)])\n",
    "# mol.load_new(trajectory - np.mean(trajectory, axis=1, keepdims=True)) ### view trajectories \n",
    "mol.load_new(structure) ### view structures\n",
    "view = nv.show_mdanalysis(mol)\n",
    "view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a247df1-f33b-447c-8039-1a47334d4c98",
   "metadata": {},
   "source": [
    "### Graph Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2148bd80-971a-4baa-bfa6-5628d60a3968",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../results/structure_rendering/result_geodiff_test_smiles.pkl', 'rb') as f:\n",
    "# with open(f'results/structure_rendering/result_geodiff_test_smiles_fps.pkl', 'rb') as f:\n",
    "    results_dict = pkl.load(f)\n",
    "\n",
    "test_smileses = results_dict['smiles']\n",
    "constituents = results_dict['constituents']\n",
    "conditional_infos = results_dict['conditional_infos']\n",
    "structures = results_dict['structures']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa47af03-4831-44b1-a282-0fa40e5ab972",
   "metadata": {},
   "source": [
    "#### Evaluation on Molecular Physics Instability (MPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf40225-66f8-401a-b16a-cd77a1598539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Xponge\n",
    "from Xponge.helper import rdkit as Xponge_rdkit_helper\n",
    "from graph_assembler.graph_assembler import assemble_mol_graph, check_bonds, get_rotable_bonds, get_rotable_dihedrals, uff_eval\n",
    "from functools import reduce\n",
    "import warnings\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*') ### disable rdkit warning\n",
    "from multiprocessing import Pool ### enabling multiprocess\n",
    "\n",
    "def assemble_fn(arg_dict):\n",
    "    mol_id = arg_dict['mol_id']\n",
    "    atomic_numbers = arg_dict['atomic_numbers']\n",
    "    hydrogen_numbers = arg_dict['hydrogen_numbers']\n",
    "    mol_structures = arg_dict['structures']\n",
    "    conditional_info = arg_dict['bonds']\n",
    "\n",
    "    ret_dict = {\n",
    "        'valid_or_not': np.zeros(len(mol_structures), dtype=np.bool_),\n",
    "        'smileses': [], \n",
    "        'num_required_bonds': np.zeros(len(mol_structures), dtype=np.int32),\n",
    "        'num_satisfied_bonds': np.zeros(len(mol_structures), dtype=np.int32),\n",
    "        'rotable_bonds': [],\n",
    "        'rotable_bonds_dihedrals': [],\n",
    "        'uff_enes': [], 'uff_forces': [],\n",
    "    }\n",
    "\n",
    "    rdmols = []\n",
    "    for structure_id, structure in enumerate(mol_structures):\n",
    "        structure = structure[:len(atomic_numbers)]\n",
    "        success, Xponge_mol, smiles = assemble_mol_graph(atomic_numbers, hydrogen_numbers, structure)\n",
    "        ret_dict['valid_or_not'][structure_id] = success\n",
    "        ret_dict['smileses'].append(\"\" if not success else smiles)\n",
    "    \n",
    "        if success:\n",
    "            ##### delete Hs (Hs are added to help recogonizing topology, their coordinates are fake)\n",
    "            atoms = Xponge_mol.atoms[::1]\n",
    "            hydrogen_atom_idx = np.sort([idx for idx, atom in enumerate(atoms) if 'H' in atom])[::-1]\n",
    "            for atom_idx in hydrogen_atom_idx: \n",
    "                Xponge_mol.delete_atom(atom_idx)\n",
    "                \n",
    "            ### check bonds\n",
    "            ret = check_bonds(Xponge_mol.bonds, conditional_info, allow_perm=False)\n",
    "            ret_dict['num_required_bonds'][structure_id] = ret[0]\n",
    "            ret_dict['num_satisfied_bonds'][structure_id] = ret[1]\n",
    "\n",
    "            if ret[0] == ret[1]: \n",
    "                ### calculate dihedrals\n",
    "                mol = Xponge_rdkit_helper.assign_to_rdmol(Xponge_mol)\n",
    "                rotable_bonds = get_rotable_bonds(mol)\n",
    "                ret_dict['rotable_bonds'].append(rotable_bonds)\n",
    "                rdmols.append((mol, structure))\n",
    "\n",
    "                ### uff evaluation (MPI)\n",
    "                try:\n",
    "                    ene, force, _, _, _ = uff_eval(mol, structure)\n",
    "                    ret_dict['uff_enes'].append(ene)\n",
    "                    ret_dict['uff_forces'].append(force)\n",
    "                except: \n",
    "                    ret_dict['uff_enes'].append(None) \n",
    "                    ret_dict['uff_forces'].append(None)\n",
    "                    \n",
    "                    # warnings.warn('Failed to calculate UFF energy & force for mol {} structure {}'.format(mol_id, structure_id)) \n",
    "        else:\n",
    "            ret_dict['num_required_bonds'][:] = -1\n",
    "            ret_dict['num_satisfied_bonds'][:] = -1\n",
    "\n",
    "    rotable_bonds = reduce(lambda x, y: x | y, [set(x) for x in ret_dict['rotable_bonds']], set(ret_dict['rotable_bonds'][0]))\n",
    "    for (mol, structure) in rdmols:\n",
    "        ret_dict['rotable_bonds_dihedrals'].append(\n",
    "            get_rotable_dihedrals(mol, structure, given_bonds=conditional_info, given_rotable_bonds=rotable_bonds)\n",
    "        )\n",
    "        \n",
    "    return ret_dict\n",
    "    \n",
    "arg_dicts = []\n",
    "for mol_id, (atomic_numbers, hydrogen_numbers, mol_structures, conditional_info) in \\\n",
    "    tqdm(enumerate(zip([c['atomic_numbers'] for c in constituents],\n",
    "                       [c['hydrogen_numbers'] for c in constituents],\n",
    "                       structures, \n",
    "                       [c['bonds'] for c in conditional_infos]))):\n",
    "    arg_dicts.append(\n",
    "        {'mol_id': mol_id, 'atomic_numbers': atomic_numbers, 'hydrogen_numbers': hydrogen_numbers, \n",
    "         'structures': mol_structures, 'bonds': conditional_info}\n",
    "    )\n",
    "\n",
    "ret_dicts = []\n",
    "##### parallel code\n",
    "pool = Pool(processes=os.cpu_count())\n",
    "for d in tqdm(pool.imap(func=assemble_fn, iterable=arg_dicts),\n",
    "                   total = NSAMPLES):\n",
    "    ret_dicts.append(d)\n",
    "pool.close()\n",
    "##### serial code \n",
    "# for arg_dict in tqdm(arg_dicts):\n",
    "#     ret_dicts.append(assemble_fn(arg_dict))\n",
    "\n",
    "valid_or_not = np.stack([d['valid_or_not'] for d in ret_dicts])\n",
    "num_required_bonds = np.stack([d['num_required_bonds'] for d in ret_dicts])\n",
    "num_satisfied_bonds = np.stack([d['num_satisfied_bonds'] for d in ret_dicts])\n",
    "rotable_bonds = [d['rotable_bonds'] for d in ret_dicts]\n",
    "rotable_bonds_dihedrals = [d['rotable_bonds_dihedrals'] for d in ret_dicts]\n",
    "uff_enes = [d['uff_enes'] for d in ret_dicts]\n",
    "uff_forces = [d['uff_forces'] for d in ret_dicts]\n",
    "smileses = [d['smileses'] for d in ret_dicts]\n",
    "\n",
    "print(\"Molecular Physics Instability: {:.2f} among {} structures, {} structures per molecule\".format(\n",
    "    np.mean([np.mean(np.linalg.norm(f, axis=-1)) for f in uff_forces]), \n",
    "    NSTRUCTURES, NSTRUCTURE_PER_SAMPLE,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a00c40a-093d-4534-a505-2f36b6d3ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save analysis results\n",
    "with open(f'../results/structure_rendering/analysis_result_geodiff_smiles_rdkit.pkl', 'wb') as f:\n",
    "# with open(f'../results/structure_rendering/analysis_result_geodiff_smiles_fp_trick.pkl', 'wb') as f:\n",
    "    pkl.dump(\n",
    "        {'n_atoms': np.array([len(c['atomic_numbers']) for c in constituents], dtype=np.int32),\n",
    "         'valid_or_not': valid_or_not, \n",
    "         'num_required_bonds': num_required_bonds, \n",
    "         'num_satisfied_bonds': num_satisfied_bonds,\n",
    "         'rotable_bonds_dihedrals': rotable_bonds_dihedrals, \n",
    "         'uff_enes': uff_enes, 'uff_forces': uff_forces, }, f\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db96605d-13fb-4069-a1c1-d2ae1729428f",
   "metadata": {},
   "source": [
    "#### Evalulation on Conformational Diversity (LogNeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e20cd2-fc48-4176-b337-bd54da7b82f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../results/structure_rendering/analysis_result_geodiff_smiles_rdkit.pkl', 'rb') as f:\n",
    "    analysis_result = pkl.load(f)\n",
    "    n_atoms = analysis_result['n_atoms']\n",
    "    valid_or_not = analysis_result['valid_or_not']\n",
    "    num_required_bonds = analysis_result['num_required_bonds']\n",
    "    num_satisfied_bonds = analysis_result['num_satisfied_bonds']\n",
    "    rotable_bonds_dihedrals = analysis_result['rotable_bonds_dihedrals']\n",
    "    uff_enes = analysis_result['uff_enes']\n",
    "    uff_forces = analysis_result['uff_forces']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c11b6f-4a1b-485d-b072-3ef31ed210e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Neff calculation \n",
    "### Neff = Sum((\\sum_t^N I[D(s, t) < delta])^-1)\n",
    "from functools import reduce\n",
    "from multiprocessing import Pool ### enabling multiprocess\n",
    "\n",
    "delta = 0.3\n",
    "nstructures_per_sample_list = [8, ] # [8, 16, 32, 64, 128, 256, ..., 1024]\n",
    "def neff_fn(rotable_bond_dihedral):\n",
    "    rotable_bond_dihedral = [rd for rd in rotable_bond_dihedral if rd is not None]\n",
    "    if len(rotable_bond_dihedral) <= 0: return None\n",
    "    rotable_bonds = rotable_bond_dihedral[0].keys() # reduce(lambda x, y: x & y, [set(d.keys()) for d in rotable_bond_dihedral], set(rotable_bond_dihedral[0].keys()))\n",
    "    if len(rotable_bonds) <= 0: return None\n",
    "    dihedral_distances = []\n",
    "    for bond in rotable_bonds:\n",
    "        dihedrals = np.array([d[bond] for d in rotable_bond_dihedral], dtype=np.float32)\n",
    "        num_dihedrals = len(dihedrals)\n",
    "        dihedral_distance = [ 2 - 2 * np.cos(alpha - beta) for alpha in dihedrals for beta in dihedrals]\n",
    "        dihedral_distance = np.array(dihedral_distance).reshape(num_dihedrals, num_dihedrals)\n",
    "        dihedral_distances.append(dihedral_distance)\n",
    "    dihedral_distances = np.array(dihedral_distances)\n",
    "    neffs = []\n",
    "    for b_size in nstructures_per_sample_list:\n",
    "        structure_distance = np.max(dihedral_distances[:,:b_size, :b_size], axis=0)\n",
    "        neffs.append(np.sum(1.0 / np.sum(structure_distance < delta, axis=-1)))\n",
    "\n",
    "    return np.array(neffs)\n",
    "\n",
    "pool = Pool(processes=os.cpu_count())\n",
    "neff_arr = []\n",
    "for neff in tqdm(pool.imap(func=neff_fn, iterable=rotable_bonds_dihedrals),\n",
    "                           total=NSAMPLES):\n",
    "    neff_arr.append(neff)\n",
    "pool.close()\n",
    "\n",
    "mean_neff_arr = np.mean([x for x in neff_arr if x is not None], axis=0)\n",
    "for b_size, mean_neff in zip(nstructures_per_sample_list, mean_neff_arr):\n",
    "    print(\"Mean sampling efficiency: Neff = {:.2f} in {} structures\".format(mean_neff, b_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff1b949-cd4e-4192-99c5-fac55f9e0976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
