{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc58d4-8a22-4773-9e79-ce7702bae680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"False\"\n",
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "import pickle as pkl \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"We are now running Python in: \", sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb639c3-fbca-4597-b29f-874d2cb8399f",
   "metadata": {},
   "source": [
    "## Preparation (nets, constants, params and functional utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a786c31-35d3-4ffb-97fa-173834b2dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax \n",
    "import jax.numpy as jnp\n",
    "from functools import partial\n",
    "\n",
    "#### nets\n",
    "from cybertron.readout.naive_gfn import NaiveGraphFieldNetwork, NaiveGraphFieldConditionalNetwork\n",
    "from jax.sharding import PositionalSharding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46cdb43-fff8-4efb-89e8-33b364c25b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### setup environments (single-device or multiple-devices)\n",
    "\n",
    "NDEVICES = 1\n",
    "SHARDING = True #### you can use multiple devices\n",
    "if SHARDING:\n",
    "    NDEVICES = len(jax.devices())\n",
    "    print(\"{} DEVICES detected: {}\".format(NDEVICES, jax.devices()))\n",
    "\n",
    "rng_key = jax.random.PRNGKey(8888) #### set your random seed here\n",
    "np.random.seed(7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312a1ba4-ccea-4b7d-a60d-49f91628ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### constants\n",
    "constituent_types = ['', 'O3H2', 'N2H2', 'CarH1', 'N2H1', 'NamH0', 'Oco2H0', 'N3H3', 'N4H3', 'C1H0', 'N2H0', 'Npl3H0', 'NarH1', 'O3H1', 'C2H0', 'O3H0', 'N4H1', 'CcatH0', 'N4H2', 'CarH0', 'N3H2', 'NamH2', 'C3H1', 'Npl3H2', 'NamH1', 'C2H2', 'N3H1', 'C3H3', 'C1H1', 'C3H2', 'N1H0', 'N3H0', 'FH0', 'C2H1', 'C3H0', 'C3H4', 'NarH0', 'O2H0', 'Npl3H3', 'Npl3H1', 'O2H1']\n",
    "constituent_types.sort()\n",
    "max_num_atoms = 9\n",
    "num_experts = 2\n",
    "\n",
    "#### setup & load trained models\n",
    "cutoffs = [10.0, 15.0]\n",
    "noise_thresholds = [0.5]\n",
    "arg_dicts = {\n",
    "    \"num_atom_types\": len(constituent_types), \n",
    "    \"dim_atom_feature\": 128, \n",
    "    \"dim_edge_feature\": 128, \n",
    "    \"dim_atom_filter\": 128, \n",
    "    \"num_rbf_basis\": 128, \n",
    "    \"n_interactions\": 6, \n",
    "}\n",
    "nets = [NaiveGraphFieldNetwork(**arg_dicts, cutoff=c) for c in cutoffs]\n",
    "\n",
    "param_paths = [\"../params/qm9/naive_gfn_params/naive_gfn_track_1_jax.pkl\", \"../params/qm9/naive_gfn_params/naive_gfn_track_2_jax.pkl\"]\n",
    "params = []\n",
    "for path in param_paths:\n",
    "    with open(path, 'rb') as f: \n",
    "        params.append(pkl.load(f))\n",
    "if SHARDING:\n",
    "    ##### replicate params\n",
    "    global_sharding = PositionalSharding(jax.devices()).reshape(NDEVICES, 1)\n",
    "    params = jax.device_put(params, global_sharding.replicate())\n",
    "score_fns = [partial(net.apply, p) for net, p in zip(nets, params)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8450a7b-07e9-48de-9a37-c2a26888e0eb",
   "metadata": {},
   "source": [
    "## Unconditional Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0595b5ed-784d-4d1b-b6f3-610b0b2c10fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "NSAMPLE_PER_DEVICE = 128\n",
    "NSAMPLES = NSAMPLE_PER_DEVICE * NDEVICES\n",
    "NATOMS = max_num_atoms\n",
    "\n",
    "#### jit and vmap functions (mixture of experts)\n",
    "def score_forward_fn(x, atom_type, sigma):\n",
    "    cond_list = [sigma < noise_thresholds[0],] + \\\n",
    "                [jnp.logical_and(sigma >= noise_thresholds[i], sigma < noise_thresholds[i+1]) for i in range(0, len(noise_thresholds) - 1)] + \\\n",
    "                [sigma >= noise_thresholds[-1],]\n",
    "    value_list = [fn(x, atom_type) for fn in score_fns]\n",
    "    \n",
    "    return jnp.sum(jnp.array(cond_list, dtype=jnp.float32)[..., None, None] * \\\n",
    "                    jnp.array(value_list, jnp.float32), axis=0)\n",
    "    \n",
    "#### Langevin dynamics iteration\n",
    "def Langevin_one_step_fn(x, atom_type, rng_key, sigma, alpha):\n",
    "    dx = score_forward_fn(x, atom_type, sigma)\n",
    "    rng_key, normal_key = jax.random.split(rng_key)\n",
    "    z = jax.random.normal(normal_key, shape=x.shape, dtype=jnp.float32)\n",
    "    x = x + jnp.sqrt(2 * alpha) * z - alpha * dx / sigma\n",
    "    return x, rng_key\n",
    "\n",
    "score_forward_fn_jvj = jax.jit(jax.vmap(jax.jit(score_forward_fn),\n",
    "                                        in_axes=(0,0,None)))\n",
    "Langevin_one_step_fn_jvj = jax.jit(jax.vmap(jax.jit(Langevin_one_step_fn),\n",
    "                                            in_axes=(0,0,0,None,None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf02fcd-fd2b-44fa-af36-ae935da6151e",
   "metadata": {},
   "source": [
    "### Constituents Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90448228-4370-40ca-8168-4ef9df207db6",
   "metadata": {},
   "source": [
    "#### You can sample atom constituents from datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdf776a-6dde-4a73-92af-add408031ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "constituents = np.load(\"../moledit_dataset/constituents/qm9_constituents.npy\")\n",
    "index = np.random.choice(np.arange(constituents.shape[0]), NSAMPLES)\n",
    "constituents = constituents[index]\n",
    "\n",
    "print(\"Example constituents: \")\n",
    "print(\"\\t{}\".format(\" \".join([constituent_types[i] for i in constituents[0] if i > 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6c9b38-8099-4bf9-ad60-8d50ec5b7207",
   "metadata": {},
   "source": [
    "#### You can sample atom constituents from constituents model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c94198-83dd-435f-8e21-1624ebfca850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snail.snail import SNAIL\n",
    "\n",
    "# model \n",
    "constituent_model = SNAIL(len(constituent_types), n_res_layers=5, n_attn_layers=12)\n",
    "with open(\"../params/qm9/snail_params/snail_jax.pkl\", 'rb') as f:\n",
    "    constituent_model_params = pkl.load(f)\n",
    "sample_fn = jax.jit(jax.vmap(jax.jit(partial(constituent_model.apply, \n",
    "                                             constituent_model_params))))\n",
    "\n",
    "# sampling\n",
    "x = jnp.zeros((NSAMPLES, max_num_atoms), dtype=jnp.float32)\n",
    "out = jnp.zeros((NSAMPLES, max_num_atoms), dtype=jnp.int32)\n",
    "if SHARDING:\n",
    "    global_sharding = PositionalSharding(jax.devices()).reshape(NDEVICES, 1)\n",
    "    x = jax.device_put(x, global_sharding.replicate())\n",
    "    out = jax.device_put(out, global_sharding.replicate())\n",
    "\n",
    "for atom in tqdm(range(max_num_atoms)):\n",
    "    logits = sample_fn(x)\n",
    "    sample_key, rng_key = jax.random.split(rng_key)\n",
    "    sampled_c = jax.random.categorical(sample_key, logits[:, atom, :], axis=-1)\n",
    "\n",
    "    out = out.at[:, atom].set(sampled_c)\n",
    "    x = x.at[:, atom].set(sampled_c.astype(jnp.float32) / (len(constituent_types) - 1) * 2 - 1)\n",
    "    \n",
    "constituents = np.array(out)\n",
    "print(\"Example constituents: \")\n",
    "print(\"\\t{}\".format(\" \".join([constituent_types[i] for i in constituents[0] if i > 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bef43f5-1696-4331-9f47-b8a8c47c3bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### or... you can design yourself!\n",
    "#### remember setting constituents of padding atoms to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d99707-8391-4289-b9c4-fad34e8feb2a",
   "metadata": {},
   "source": [
    "### Structure Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fb4fc9-c6ea-40cb-8fab-490bfbb26343",
   "metadata": {},
   "source": [
    "#### ALD-based Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a41b502-1cfb-4101-9396-335eab24e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps, n_eq_steps = 1000, 10 \n",
    "sigma_min, sigma_max = 0.01, 5.0\n",
    "noise_scales = \\\n",
    "    np.exp(np.linspace(np.log(sigma_min), np.log(sigma_max), n_steps))\n",
    "\n",
    "def Langevin_inference(x_t, atom_type, rng_keys, save_traj=False):\n",
    "    epsilon = 2e-4\n",
    "    trajectory = []\n",
    "    for t in tqdm(range(n_steps)):\n",
    "        sigma_t = noise_scales[n_steps-t-1]\n",
    "        alpha = epsilon * sigma_t * sigma_t / (sigma_min * sigma_min)\n",
    "        for k in range(n_eq_steps):\n",
    "            x_t, rng_keys = Langevin_one_step_fn_jvj(x_t, atom_type, \n",
    "                                                     rng_keys, sigma_t, alpha)\n",
    "            if save_traj: trajectory.append(x_t)\n",
    "            \n",
    "    dx = jax.vmap(score_forward_fn, in_axes=(0, 0, None))(x_t, atom_type, sigma_min)\n",
    "    x_t = x_t - sigma_min * dx\n",
    "    if save_traj: trajectory.append(x_t)\n",
    "\n",
    "    return x_t, trajectory, rng_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9b5ff4-38d4-432b-9296-606a8620bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "### prepare rng keys for sampling\n",
    "split_rng_keys = jax.random.split(rng_key, NSAMPLES +1)\n",
    "rng_keys = split_rng_keys[:NSAMPLES]\n",
    "rng_key = split_rng_keys[-1]\n",
    "rng_key, normal_key = jax.random.split(rng_key)\n",
    "x_t = jax.random.normal(normal_key, shape=(NSAMPLES,9,3), dtype=jnp.float32)\n",
    "\n",
    "if SHARDING: \n",
    "    global_sharding = PositionalSharding(jax.devices()).reshape(-1, 1)\n",
    "    constituents = jax.device_put(constituents, global_sharding.replicate())\n",
    "    rng_keys = jax.device_put(rng_keys, global_sharding.replicate())\n",
    "    x_t = jax.device_put(x_t, global_sharding.replicate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d989aef5-9022-4c44-92ca-653d454a9e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures, trajectories, rng_keys = Langevin_inference(x_t, constituents, rng_keys,\n",
    "                                                        save_traj=True)\n",
    "structures, trajectories = jax.tree_map(np.array, (structures, trajectories))\n",
    "\n",
    "#### save results \n",
    "with open(f'../results/qm9/results.pkl', 'wb') as f: \n",
    "    pkl.dump(jax.tree_map(np.array, \n",
    "                          {'constituents': constituents,\n",
    "                           'trajectories': trajectories, 'structures': structures}), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0996b575-bc33-46ef-a824-c3c778c9237d",
   "metadata": {},
   "source": [
    "#### DPM-based Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06494ae-1494-4bf6-99da-0b46e1234e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DPM_3, n_eq_steps = 7, 10 \n",
    "sigma_min, sigma_max = 0.01, 5.0\n",
    "\n",
    "def DPM_3_inference(x_t, atom_type, rng_keys):\n",
    "    r1 = 1.0 / 3.0\n",
    "    r2 = 2.0 / 3.0\n",
    "    lambda_max = np.log(1.0 / sigma_min)\n",
    "    lambda_min = np.log(1.0 / sigma_max)\n",
    "    h = (lambda_max - lambda_min) / N_DPM_3\n",
    "    epsilon = 2e-4\n",
    "\n",
    "    trajectory = []\n",
    "    lambda_t = lambda_min\n",
    "    sigma_t = 1.0 / np.exp(lambda_t) \n",
    "    \n",
    "    for t in tqdm(range(N_DPM_3)):\n",
    "        sigma_s1 = 1.0 / np.exp(lambda_t + r1 * h)\n",
    "        sigma_s2 = 1.0 / np.exp(lambda_t + r2 * h)\n",
    "\n",
    "        dx1 = score_forward_fn_jvj(x_t, atom_type, sigma_t)\n",
    "        u1 = x_t - sigma_s1 * (np.exp(r1 * h) - 1) * dx1 \n",
    "\n",
    "        dx2 = score_forward_fn_jvj(u1, atom_type, sigma_s1)\n",
    "        D1 = dx2 - dx1 \n",
    "\n",
    "        u2 = x_t - sigma_s2 * (np.exp(r2 * h) - 1) * dx1\\\n",
    "            - sigma_s2 * r2 / r1 * ( (np.exp(r2 * h) - 1) / (r2 * h) - 1) * D1\n",
    "\n",
    "        dx3 = score_forward_fn_jvj(u2, atom_type, sigma_s2)\n",
    "\n",
    "        D2 = dx3 - dx1 \n",
    "        lambda_t += h \n",
    "        sigma_t = 1.0 / np.exp(lambda_t)\n",
    "        x_t = x_t - sigma_t * (np.exp(h) - 1) * dx1 - sigma_t / r2 * ((np.exp(h) - 1) / h - 1) * D2\n",
    "        trajectory.append(x_t)\n",
    "\n",
    "        alpha = epsilon * sigma_t * sigma_t / (sigma_min * sigma_min)\n",
    "        for k in range(n_eq_steps):\n",
    "            x_t, rng_keys = Langevin_one_step_fn_jvj(x_t, atom_type, \n",
    "                                                     rng_keys, sigma_t, alpha)\n",
    "            trajectory.append(x_t)\n",
    "            \n",
    "    dx = jax.vmap(score_forward_fn, in_axes=(0, 0, None))(x_t, atom_type, sigma_min)\n",
    "    x_t = x_t - sigma_min * dx\n",
    "    trajectory.append(x_t)\n",
    "\n",
    "    return x_t, trajectory, rng_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9a5f6f-9810-4227-a062-311e0b451865",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key, normal_key = jax.random.split(rng_key)\n",
    "x_t = jax.random.normal(normal_key, (NSAMPLES, NATOMS, 3)) * sigma_max\n",
    "\n",
    "rng_keys = jax.random.split(rng_key, 1+NSAMPLES)\n",
    "rng_key, rng_keys = rng_keys[-1], rng_keys[:-1]\n",
    "\n",
    "if SHARDING:\n",
    "    constituents = jax.device_put(constituents, global_sharding.replicate())\n",
    "    x_t = jax.device_put(x_t, global_sharding.replicate())\n",
    "    rng_keys = jax.device_put(rng_keys, global_sharding.replicate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e63598f-6b18-48b2-bd97-522443cc7604",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures, trajectories, rng_keys = DPM_3_inference(x_t, constituents, rng_keys)\n",
    "structures, trajectories = jax.tree_map(np.array, (structures, trajectories))\n",
    "\n",
    "#### save results \n",
    "with open(f'../results/qm9/results.pkl', 'wb') as f: \n",
    "    pkl.dump(jax.tree_map(np.array, \n",
    "                          {'constituents': constituents,\n",
    "                           'trajectories': trajectories, 'structures': structures}), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871b2cf0-01b7-4a7d-aa0b-d46f93b3d100",
   "metadata": {},
   "source": [
    "### Graph Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6464272f-2ef2-44f8-8e41-ea3fc73cab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Xponge\n",
    "from graph_assembler.graph_assembler import assemble_mol_graph\n",
    "\n",
    "#### load your results \n",
    "with open(f'../results/qm9/results.pkl', 'rb') as f: \n",
    "    results = pkl.load(f)\n",
    "    constituents = results['constituents']\n",
    "    trajectories = results['trajectories']\n",
    "    structures = results['structures']\n",
    "\n",
    "element_table = {\n",
    "    'C': 6, 'N': 7, 'O': 8, 'F': 9\n",
    "}\n",
    "\n",
    "success_or_not = []\n",
    "smileses = []\n",
    "\n",
    "if not os.path.exists('../results/qm9/mol2'):\n",
    "    os.mkdir('../results/qm9/mol2')\n",
    "    \n",
    "for i, (constituent, structure) in tqdm(enumerate(zip(constituents, structures))):\n",
    "    constituent_str = [constituent_types[c] for c in constituent if c > 0]\n",
    "    atomic_numbers = [element_table[x[0]] for x in constituent_str]\n",
    "    hydrogen_numbers = [int(x[-1]) for x in constituent_str]\n",
    "    \n",
    "    success, Xponge_mol, smiles = assemble_mol_graph(atomic_numbers, hydrogen_numbers, structure)\n",
    "    success_or_not.append(success) \n",
    "    smileses.append(\"\" if not success else smiles)\n",
    "    \n",
    "    #### export to mol2\n",
    "    if success:\n",
    "        ##### delete Hs (Hs are added to help recogonizing topology, their coordinates are fake)\n",
    "        atoms = Xponge_mol.atoms[::1]\n",
    "        hydrogen_atom_idx = np.sort([idx for idx, atom in enumerate(atoms) if 'H' in atom])[::-1]\n",
    "        for atom_idx in hydrogen_atom_idx: \n",
    "            Xponge_mol.delete_atom(atom_idx)\n",
    "        Xponge_mol.save_as_mol2('../results/qm9/mol2/{}.mol2'.format(i), atomtype=None)\n",
    "        \n",
    "with open('../results/qm9/result.smi', 'w') as f:\n",
    "    for smiles in smileses:\n",
    "        f.write(\"{}\\n\".format(smiles))\n",
    "        \n",
    "print(\".mol2 files are saved in ../results/qm9/mol2\")\n",
    "print(\"smiles are saved in ../results/qm9/result.smi\")\n",
    "print(\"valid: {:.2f}, unique and valid: {:.2f} among {} samples\".format(\n",
    "    np.sum(success_or_not) / NSAMPLES, \n",
    "    np.sum(np.unique(smileses) != '') / NSAMPLES,\n",
    "    NSAMPLES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aab7b37-b515-4143-87fe-26e567713251",
   "metadata": {},
   "source": [
    "### View Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6f368-c3a2-4c80-9490-9134482c9389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### view trajectories | structures\n",
    "import MDAnalysis as mda \n",
    "import nglview as nv \n",
    "\n",
    "#### load your results \n",
    "with open(f'../results/qm9/results.pkl', 'rb') as f: \n",
    "    results = pkl.load(f)\n",
    "    constituents = results['constituents']\n",
    "    trajectories = results['trajectories']\n",
    "    structures = results['structures']\n",
    "\n",
    "mol_id = 0\n",
    "constituent = constituents[mol_id]\n",
    "n_atoms = np.sum(constituent > 0)\n",
    "constituent = constituent[:n_atoms]\n",
    "structure = np.array(structures)[mol_id, :n_atoms, :]\n",
    "structure = structure - np.mean(structure, axis=0, keepdims=True)\n",
    "rg = np.sqrt(np.sum(structure ** 2) / n_atoms)\n",
    "trajectory = np.array(trajectories)[:, mol_id, :n_atoms, :]\n",
    "trajectory = trajectory - np.mean(trajectory, axis=1, keepdims=True)\n",
    "print(\"This is a molecule with {} atoms, rg = {:.2f} ang\".format(n_atoms, rg))\n",
    "print(\"WARNING: bonds provided by NGLViewer may be problematic\")\n",
    "\n",
    "mol = mda.Universe.empty(n_atoms=n_atoms)\n",
    "mol.add_TopologyAttr('names', [constituent_types[i] for i in constituent])\n",
    "# mol.load_new(trajectory - np.mean(trajectory, axis=1, keepdims=True)) ### view trajectories \n",
    "mol.load_new(structure) ### view structures\n",
    "view = nv.show_mdanalysis(mol)\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb38b57-e9b4-4fcd-80bb-53cba3cee34f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
