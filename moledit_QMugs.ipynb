{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"False\"\n",
    "import sys \n",
    "sys.path.append(\".\")\n",
    "import math\n",
    "import pickle as pkl \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"We are now running Python in: \", sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation (nets, constants, params and functional utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax \n",
    "import jax.numpy as jnp\n",
    "\n",
    "from functools import partial\n",
    "from cybertron.common.config_load import load_config\n",
    "\n",
    "#### load nets\n",
    "from train.train import MolEditScoreNet\n",
    "from cybertron.model.molct_plus import AdaLNMolCT_Plus\n",
    "from cybertron.readout import AdaLNGFNReadout\n",
    "\n",
    "from train.utils import set_dropout_rate_config\n",
    "from jax.sharding import PositionalSharding\n",
    "\n",
    "def _sharding(input, shards):\n",
    "\n",
    "    n_device = shards.shape[0]\n",
    "    if isinstance(input, (np.ndarray, jax.Array)):\n",
    "        _shape = [n_device, ] + [1 for _ in range(input.ndim - 1)]\n",
    "        return jax.device_put(input, shards.reshape(_shape))\n",
    "    elif input is None:\n",
    "        return jax.device_put(input, shards)\n",
    "    else:\n",
    "        raise TypeError(f\"Invalid input: {input}\")\n",
    "\n",
    "from inference.inference import DPM_3_inference, Langevin_inference, DPM_pp_2S_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDEVICES = 1\n",
    "NATOMS = 64\n",
    "SHARDING = True #### you can use multiple devices\n",
    "if SHARDING:\n",
    "    NDEVICES = len(jax.devices())\n",
    "    print(\"{} DEVICES detected: {}\".format(NDEVICES, jax.devices()))\n",
    "\n",
    "def split_rngs(rng_key, shape):\n",
    "    size = np.prod(shape)\n",
    "    rng_keys = jax.random.split(rng_key, size + 1)\n",
    "    return rng_keys[:-1].reshape(shape + (-1,)), rng_keys[-1]\n",
    "\n",
    "rng_key = jax.random.PRNGKey(8888) #### set your random seed here\n",
    "np.random.seed(7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### initialize models\n",
    "encoder_config = load_config(\"config/molct_plus.yaml\")\n",
    "gfn_config = load_config(\"config/gfn.yaml\")\n",
    "gfn_config.model.num_atoms = 128\n",
    "gfn_n_interactions = [4, 4, 3]\n",
    "\n",
    "modules = []\n",
    "for n_inter in gfn_n_interactions:\n",
    "    gfn_config.settings.n_interactions = n_inter\n",
    "    modules.append({\n",
    "        \"encoder\": {\"module\": AdaLNMolCT_Plus, \n",
    "                    \"args\": {\"config\": encoder_config}},\n",
    "        \"gfn\": {\"module\": AdaLNGFNReadout, \n",
    "                \"args\": {\"config\": gfn_config}}\n",
    "    })\n",
    "\n",
    "##### load params\n",
    "load_ckpt_paths = ['./params/QMugs/structure_model/moledit_params_track1.pkl', \n",
    "                   './params/QMugs/structure_model/moledit_params_track2.pkl',\n",
    "                   './params/QMugs/structure_model/moledit_params_track3.pkl'] \n",
    "noise_thresholds = [0.35, 1.95]\n",
    "\n",
    "params = []\n",
    "for path in load_ckpt_paths:\n",
    "    with open(path, 'rb') as f: \n",
    "        params.append(pkl.load(f))\n",
    "    \n",
    "if SHARDING:\n",
    "    ##### replicate params\n",
    "    global_sharding = PositionalSharding(jax.devices()).reshape(NDEVICES, 1)\n",
    "    params = jax.device_put(params, global_sharding.replicate())\n",
    "\n",
    "for param, module in zip(params, modules):\n",
    "    for k, v in module.items():\n",
    "        module[k]['args']['config'] = \\\n",
    "            set_dropout_rate_config(module[k]['args']['config'], 0.0)\n",
    "        module[k][\"module\"] = v[\"module\"](**v[\"args\"])\n",
    "        partial_params = {\"params\": param[\"params\"]['score_net'].pop(k)}\n",
    "        module[k][\"callable_fn\"] = partial(module[k][\"module\"].apply, partial_params)\n",
    "\n",
    "moledit_scorenets = [MolEditScoreNet(\n",
    "        encoder=modules[k]['encoder']['callable_fn'],\n",
    "        gfn=modules[k]['gfn']['callable_fn'],\n",
    "        with_cond = True,\n",
    "    ) for k in range(len(load_ckpt_paths))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Sample atom constituents from constituent model\n",
    "from config.transformer_config import transformer_config\n",
    "from transformer.prefix_model import Transformer, TransformerConfig\n",
    "\n",
    "with open('params/QMugs/constituents_model/constituents_vocab.pkl', 'rb') as f:\n",
    "    constituent_vocab_list = pkl.load(f)\n",
    "NCONSTITUENTS = len(constituent_vocab_list) # 30\n",
    "NRG_TOKENS = 3 # seq_len = 30 + 3\n",
    "SEQ_LEN = NCONSTITUENTS + NRG_TOKENS\n",
    "\n",
    "NRG_VOCABS = 11\n",
    "transformer_config.deterministic = True\n",
    "transformer_config.dtype = jnp.float32\n",
    "transformer = Transformer(\n",
    "    config=TransformerConfig(\n",
    "            **{\n",
    "                **transformer_config,\n",
    "                \"vocab_size\": 64 + NRG_VOCABS + 1, \n",
    "                \"output_vocab_size\": 64 + NRG_VOCABS + 1}, )\n",
    ")\n",
    "\n",
    "##### load params\n",
    "with open(\"params/QMugs/constituents_model/moledit_params.pkl\", \"rb\") as f:\n",
    "    params = pkl.load(f)\n",
    "    params = jax.tree_util.tree_map(lambda x: jnp.array(x), params)\n",
    "\n",
    "if SHARDING:\n",
    "    ##### replicate params\n",
    "    global_sharding = PositionalSharding(jax.devices()).reshape(NDEVICES, 1)\n",
    "    params = jax.device_put(params, global_sharding.replicate())\n",
    "\n",
    "def top_p_sampling(logits, rng_key, p=0.9):\n",
    "    sorted_indices = jnp.argsort(logits)\n",
    "    sorted_logits = logits[sorted_indices]\n",
    "    sorted_probs = jax.nn.softmax(sorted_logits)\n",
    "    cum_probs = jnp.cumsum(sorted_probs)\n",
    "    invalid_mask = cum_probs < (1-p)\n",
    "    \n",
    "    rng_key, sample_key = jax.random.split(rng_key)\n",
    "    sampled_token = jax.random.categorical(sample_key, sorted_logits+invalid_mask.astype(jnp.float32)*(-1e5))\n",
    "    \n",
    "    return sorted_indices[sampled_token], rng_key \n",
    "        \n",
    "##### prepare functions, jit & vmap\n",
    "jitted_logits_fn = jax.jit(transformer.apply)\n",
    "top_p_sampling_fn = jax.vmap(jax.vmap(jax.jit(partial(top_p_sampling, p=0.9))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Property-guided Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSAMPLE_PER_DEVICE = 8 # 128\n",
    "NSAMPLES = NSAMPLE_PER_DEVICE * NDEVICES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_properties = [\n",
    "    'mw', 'rotatable_bonds', 'rings', 'hbond_acceptors', 'hbond_donors', \n",
    "    'LogP', 'TPSA', 'DFT_DIPOLE_TOT', 'DFT_HOMO_LUMO_GAP'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Sample properties from datasets\n",
    "with open(\"./moledit_dataset/property/QMugs.pkl\", \"rb\") as f:\n",
    "    property_dict = pkl.load(f)\n",
    "\n",
    "properties = [\n",
    "    {p: property_dict[k][p] for p in required_properties} for  k in \n",
    "    np.random.choice(list(property_dict.keys()), NSAMPLE_PER_DEVICE * NDEVICES)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constituents Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.constants import property_info\n",
    "\n",
    "def process_a_property(data_property, property_mask_type=\"no_mask\"):\n",
    "    prefix_len = len(required_properties)\n",
    "    dim_prefix_emb = len(property_info[required_properties[0]]['rbf_centers'])\n",
    "    \n",
    "    if property_mask_type == 'all_mask':\n",
    "        prefix = np.zeros((prefix_len, dim_prefix_emb), dtype=np.float32)\n",
    "        prefix_mask = np.zeros(len(required_properties), dtype=np.bool_)\n",
    "        \n",
    "        return {'prefix': prefix, 'prefix_mask': prefix_mask}\n",
    "\n",
    "    mask_prob = 0.0 if property_mask_type == 'no_mask' else 0.5\n",
    "    prefix = []\n",
    "    prefix_mask = []\n",
    "    for p in required_properties:\n",
    "        if np.random.rand() < mask_prob:\n",
    "            prefix.append(np.zeros(dim_prefix_emb, dtype=np.float32))\n",
    "            prefix_mask.append(False)\n",
    "        else:\n",
    "            p_val = data_property[p]\n",
    "            p_val = (p_val - property_info[p]['mean']) / property_info[p]['std']\n",
    "            rbf_centers = property_info[p]['rbf_centers']\n",
    "            rbf_sigma = property_info[p]['rbf_sigma']\n",
    "            prefix.append(1.0 / np.sqrt(2 * np.pi * rbf_sigma) * np.exp(-0.5 * ((p_val - rbf_centers) / rbf_sigma) ** 2))\n",
    "            prefix_mask.append(True)\n",
    "            \n",
    "    return {\n",
    "        'prefix': np.array(prefix, dtype=np.float32), \n",
    "        'prefix_mask': np.array(prefix_mask, dtype=np.bool_)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_dicts = [process_a_property(p) for p in properties]\n",
    "prefix_dict = {k: np.array([d[k] for d in prefix_dicts]) for k in ['prefix', 'prefix_mask']}\n",
    "\n",
    "for k, v in prefix_dict.items(): print(k, v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {\n",
    "    \"inputs\": jnp.ones((NSAMPLES, SEQ_LEN), dtype=jnp.int32), \n",
    "    \"prefix\": jnp.array(prefix_dict[\"prefix\"]), \n",
    "    \"prefix_mask\": jnp.array(prefix_dict[\"prefix_mask\"]),\n",
    "    \"generation_result\": jnp.ones((NSAMPLES, SEQ_LEN), dtype=jnp.int32)\n",
    "}\n",
    "input_dict[\"inputs\"] = input_dict[\"inputs\"].at[:, NCONSTITUENTS:].set(64 + NRG_VOCABS) #### unk token for rg\n",
    "\n",
    "rng_keys = jax.random.split(rng_key, NSAMPLES*SEQ_LEN + 1)\n",
    "rng_keys, rng_key = rng_keys[:NSAMPLES*SEQ_LEN].reshape(NSAMPLES, SEQ_LEN, -1), rng_keys[-1]\n",
    "\n",
    "if SHARDING:\n",
    "    #### shard inputs \n",
    "    ds_sharding = partial(_sharding, shards=global_sharding)\n",
    "    input_dict = jax.tree_map(ds_sharding, input_dict)\n",
    "    rng_keys = ds_sharding(rng_keys)\n",
    "\n",
    "inv_temperature = 1.25\n",
    "for step in tqdm(range(SEQ_LEN)):\n",
    "    logits = jitted_logits_fn(params, \n",
    "                              input_dict['inputs'],\n",
    "                              input_dict['generation_result'], \n",
    "                              input_dict['prefix'], \n",
    "                              input_dict['prefix_mask'])\n",
    "    if step >= NCONSTITUENTS:\n",
    "        valid_logits_mask = jnp.zeros_like(logits, dtype=jnp.float32).at[..., -NRG_VOCABS:-1].set(1)\n",
    "    else:\n",
    "        valid_logits_mask = jnp.zeros_like(logits, dtype=jnp.float32).at[..., 1:-NRG_VOCABS].set(1)\n",
    "    logits += (-1e5) * (1.0 - valid_logits_mask)\n",
    "    sampled_token, rng_keys = top_p_sampling_fn(logits * inv_temperature, rng_keys)\n",
    "    input_dict['generation_result'] = input_dict['generation_result'].at[..., step].set(sampled_token[..., step])\n",
    "\n",
    "generation_result = np.array(input_dict['generation_result']) - 1\n",
    "constituents = []\n",
    "for seq in tqdm(generation_result):\n",
    "    atomic_numbers, hydrogen_numbers, hybridizations = [], [], []\n",
    "    n_atoms = 0\n",
    "    #### decode constituents\n",
    "    for token, num in zip(constituent_vocab_list, seq[:NCONSTITUENTS]):\n",
    "        atomic_number, hydrogen_number, hybridization = tuple([int(x) for x in token.split('_')])\n",
    "        atomic_numbers += [atomic_number,] * num \n",
    "        hydrogen_numbers += [hydrogen_number,] * num \n",
    "        hybridizations += [hybridization,] * num\n",
    "        n_atoms += num \n",
    "        \n",
    "    #### decode rg\n",
    "    rg_seq = seq[-NRG_TOKENS:] - 64\n",
    "    # print(rg_seq)\n",
    "    rg = np.exp(rg_seq[0]) * float(\"{}.{}\".format(rg_seq[1], \"\".join([str(x) for x in rg_seq[2:]])))\n",
    "    constituents.append(\n",
    "        {\"atomic_numbers\": np.array(atomic_numbers, dtype=np.uint8), \n",
    "         \"hydrogen_numbers\": np.array(hydrogen_numbers, dtype=np.uint8),\n",
    "         \"hybridizations\": np.array(hybridizations, dtype=np.uint8), \n",
    "         \"radius_of_gyrations\": np.array([rg], dtype=np.float32)}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### attach properties \n",
    "for c, p in zip(constituents, properties): c.update(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PeriodicTable = Chem.GetPeriodicTable()\n",
    "\n",
    "def calculate_mw(c):\n",
    "    mw = np.sum([PeriodicTable.GetAtomicWeight(PeriodicTable.GetElementSymbol(int(x))) for x in c['atomic_numbers']])\n",
    "    mw += np.sum(c['hydrogen_numbers']) * PeriodicTable.GetAtomicWeight('H')\n",
    "    return mw\n",
    "\n",
    "mw_x = [p['mw'] for p in properties]\n",
    "mw_y = [calculate_mw(c) for c in constituents]\n",
    "plt.scatter(mw_x, mw_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NATOMS = 128\n",
    "INFERENCE_METHOD = \"DPM_3\"\n",
    "\n",
    "#### jit and vmap functions\n",
    "def score_forward_fn(atom_feat, bond_feat, x, atom_mask, sigma, rg, prop):\n",
    "    cond_list = [sigma < noise_thresholds[0],] + \\\n",
    "                [jnp.logical_and(sigma >= noise_thresholds[i], sigma < noise_thresholds[i+1]) for i in range(0, len(noise_thresholds) - 1)] + \\\n",
    "                [sigma >= noise_thresholds[-1],]\n",
    "    value_list = [net.apply(\n",
    "                    {}, atom_feat, bond_feat, x, atom_mask, sigma, rg, prop)[-1] for net in moledit_scorenets]\n",
    "    \n",
    "    return jnp.sum(jnp.array(cond_list, dtype=jnp.float32)[..., None, None] * \\\n",
    "                    jnp.array(value_list, jnp.float32), axis=0)\n",
    "\n",
    "score_forward_fn_jvj = jax.jit(jax.vmap(jax.jit(score_forward_fn)))\n",
    "if INFERENCE_METHOD == \"DPM_3\":\n",
    "    inference_fn = partial(DPM_3_inference, score_fn=score_forward_fn_jvj, \n",
    "                           n_steps=20, shard_inputs=SHARDING)\n",
    "elif INFERENCE_METHOD == \"Langevin\":\n",
    "    inference_fn = partial(Langevin_inference, score_fn=score_forward_fn_jvj, \n",
    "                           n_steps=1000, shard_inputs=SHARDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example constituents: \")\n",
    "print(\"\\tatomic numbers: \", constituents[0]['atomic_numbers'])\n",
    "print(\"\\thydrogen numbers: \", constituents[0]['hydrogen_numbers'])\n",
    "print(\"\\thybridizaions: \", constituents[0]['hybridizations'])\n",
    "print(\"\\t**REMARK**: hybridization symbols are same with RDkit\")\n",
    "\n",
    "from inference.utils import preprocess_data_with_property\n",
    "\n",
    "print(\"Preprocessing inputs\")\n",
    "input_dicts = [preprocess_data_with_property(c, NATOMS, properties=[\n",
    "    'rotatable_bonds', 'rings',\n",
    "    'LogP', 'TPSA', 'DFT_DIPOLE_TOT', 'DFT_HOMO_LUMO_GAP']) for c in tqdm(constituents)]\n",
    "input_dict = {\n",
    "    k: np.stack([d[k] for d in input_dicts]) for k in input_dicts[0].keys()\n",
    "}\n",
    "\n",
    "print(\"input shape & dtypes: \")\n",
    "for k, v in input_dict.items():\n",
    "    print(\"\\t{} shape: {} dtype: {}\".format(k, v.shape, v.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = jax.tree_map(lambda x:jnp.array(x), input_dict)\n",
    "#### JAX compiles a jitted function when you call it first time.\n",
    "#### so it will be slow when you run this block first time.\n",
    "structures, trajectories, rng_key = inference_fn(input_dict, rng_key)\n",
    "\n",
    "#### save results \n",
    "with open('results/property_guidance/property_guided_sampling.pkl', 'wb') as f: \n",
    "    pkl.dump(jax.tree_map(np.array, \n",
    "                          {'constituents': constituents, 'trajectories': trajectories, 'structures': structures}), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Xponge\n",
    "from graph_assembler.graph_assembler import assemble_mol_graph\n",
    "\n",
    "success_or_not = []\n",
    "smileses = []\n",
    "for i, (atomic_numbers, hydrogen_numbers, structure) in tqdm(enumerate(zip([c['atomic_numbers'] for c in constituents],\n",
    "                                                                           [c['hydrogen_numbers'] for c in constituents],\n",
    "                                                                           structures))):\n",
    "    success, Xponge_mol, smiles = assemble_mol_graph(atomic_numbers, hydrogen_numbers, structure)\n",
    "    success_or_not.append(success) \n",
    "    smileses.append(\"\" if not success else smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### view trajectories | structures\n",
    "import MDAnalysis as mda \n",
    "import nglview as nv \n",
    "\n",
    "#### load your results \n",
    "with open('results/property_guidance/property_guided_sampling.pkl', 'rb') as f: \n",
    "    results = pkl.load(f)\n",
    "    constituents = results['constituents']\n",
    "    trajectories = results['trajectories']\n",
    "    structures = results['structures']\n",
    "\n",
    "elements = {\n",
    "    6: 'C', 7: 'N', 8: 'O', 9: 'F', 15: 'P', 16: 'S', 17: 'Cl', \n",
    "    35: 'Br', 53: 'I'\n",
    "}\n",
    "\n",
    "mol_id = 10\n",
    "atomic_numbers = constituents[mol_id]['atomic_numbers']\n",
    "hydrogen_numbers = constituents[mol_id]['hydrogen_numbers']\n",
    "n_atoms = len(atomic_numbers)\n",
    "trajectory = np.array(trajectories)[:, mol_id, :n_atoms, :]\n",
    "structure = np.array(structures)[mol_id, :n_atoms, :]\n",
    "rg = np.sqrt(np.sum(structure ** 2) / n_atoms)\n",
    "print(\"This is a molecule with {} atoms, rg = {:.2f}/{:.2f} ang\".format(n_atoms, constituents[mol_id]['radius_of_gyrations'][0], rg))\n",
    "print(\"SMILES: {}\".format(smileses[mol_id]))\n",
    "print(\"WARNING: bonds provided by NGLViewer may be problematic\")\n",
    "\n",
    "mol = mda.Universe.empty(n_atoms=len(atomic_numbers))\n",
    "mol.add_TopologyAttr('names', [\"{}H{}\".format(elements[n], hydrogen_numbers[i]) for i, n in enumerate(atomic_numbers)])\n",
    "# mol.add_TopologyAttr('names', [\"{}\".format(elements[n]) for i, n in enumerate(atomic_numbers)])\n",
    "# mol.load_new(trajectory - np.mean(trajectory, axis=1, keepdims=True)) ### view trajectories \n",
    "mol.load_new(structure) ### view structures\n",
    "view = nv.show_mdanalysis(mol)\n",
    "view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Property Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.Descriptors import ExactMolWt\n",
    "from rdkit.Chem.Lipinski import NumRotatableBonds\n",
    "from rdkit.Chem.rdMolDescriptors import CalcNumRings\n",
    "from rdkit.Chem.Lipinski import NumHAcceptors \n",
    "from rdkit.Chem.Lipinski import NumHDonors\n",
    "from rdkit.Chem.Crippen import MolLogP\n",
    "from rdkit.Chem.Descriptors import TPSA\n",
    "\n",
    "prop_x = []\n",
    "prop_y = []\n",
    "for c, smi in zip(constituents, smileses):\n",
    "    if smi == \"\": continue \n",
    "    try:\n",
    "        prop_y.append(TPSA(Chem.MolFromSmiles(smi)))\n",
    "        prop_x.append(c['TPSA'])\n",
    "    except: continue\n",
    "\n",
    "plt.scatter(tpsa_x, tpsa_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
